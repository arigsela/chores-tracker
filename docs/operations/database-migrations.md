# Database Migrations Guide

Complete guide to managing database schema changes using Alembic in the Chores Tracker application.

## Table of Contents

- [Overview](#overview)
- [Alembic Configuration](#alembic-configuration)
- [Creating Migrations](#creating-migrations)
  - [Autogenerate Migrations](#autogenerate-migrations)
  - [Manual Migrations](#manual-migrations)
  - [Migration File Structure](#migration-file-structure)
- [Running Migrations](#running-migrations)
  - [Development (Docker Compose)](#development-docker-compose)
  - [Production (Kubernetes)](#production-kubernetes)
- [Common Migration Patterns](#common-migration-patterns)
  - [Adding a Column](#adding-a-column)
  - [Modifying a Column](#modifying-a-column)
  - [Creating a Table](#creating-a-table)
  - [Adding Indexes](#adding-indexes)
  - [Data Migrations](#data-migrations)
- [Troubleshooting](#troubleshooting)
- [Best Practices](#best-practices)

## Overview

The Chores Tracker application uses **Alembic** for database schema versioning and migrations. Alembic tracks schema changes through migration scripts and ensures your database structure stays synchronized with your SQLAlchemy models.

**Key Concepts:**
- **Migration**: A Python script that defines database schema changes (upgrade/downgrade)
- **Revision**: A unique identifier for each migration
- **Head**: The latest migration in the chain
- **Upgrade**: Apply migrations to move forward
- **Downgrade**: Reverse migrations to move backward

**Technology Stack:**
- **Alembic**: Database migration tool
- **SQLAlchemy 2.0**: ORM with async support
- **MySQL 8.0**: Database engine
- **AsyncIO**: Asynchronous database operations

## Alembic Configuration

### Directory Structure

```
backend/
├── alembic/
│   ├── versions/              # Migration scripts
│   │   ├── 1a4bc9866488_initial_migration.py
│   │   ├── 0582f39dfdd4_add_multi_assignment_support.py
│   │   └── ...
│   ├── env.py                 # Alembic environment configuration
│   └── script.py.mako         # Template for new migrations
└── alembic.ini                # Alembic configuration file
```

### Configuration Files

**`backend/alembic.ini`**: Main configuration file
```ini
[alembic]
script_location = backend/alembic
prepend_sys_path = .
sqlalchemy.url = driver://user:pass@localhost/dbname  # Overridden at runtime
```

**`backend/alembic/env.py`**: Environment setup (async support)
- Configures async SQLAlchemy engine
- Imports models via `backend.app.db.base.Base`
- Uses application settings for DATABASE_URL
- Supports both online and offline modes

### Database Connection

The migration system uses the same `DATABASE_URL` from your application settings:

```bash
# Example DATABASE_URL format
mysql+aiomysql://user:password@mysql:3306/chores_tracker
```

Alembic automatically converts async URLs to sync equivalents for migration execution.

## Creating Migrations

### Autogenerate Migrations

Alembic can automatically detect changes between your SQLAlchemy models and the database schema.

**Development (Docker Compose):**

```bash
# 1. Make changes to your SQLAlchemy models in backend/app/models/

# 2. Generate migration from model changes
docker compose exec api python -m alembic -c backend/alembic.ini revision --autogenerate -m "add user profile fields"

# 3. Review the generated migration file in backend/alembic/versions/
# IMPORTANT: Always review autogenerated migrations for accuracy
```

**Local (without Docker):**

```bash
cd /path/to/chores-tracker

# Ensure your virtual environment is activated
source venv/bin/activate

# Generate migration
python -m alembic -c backend/alembic.ini revision --autogenerate -m "add user profile fields"
```

**What Autogenerate Detects:**
- New tables and columns
- Removed tables and columns
- Column type changes
- Index additions/removals
- Foreign key changes

**What Autogenerate Does NOT Detect:**
- Column name changes (appears as remove + add)
- Table name changes (appears as drop + create)
- Constraint changes in some cases
- Data transformations

### Manual Migrations

For complex schema changes or data migrations, create an empty migration and write custom logic:

```bash
# Create empty migration
docker compose exec api python -m alembic -c backend/alembic.ini revision -m "migrate user data to new schema"
```

### Migration File Structure

Example migration file:

```python
"""add_user_profile_fields

Revision ID: abc123def456
Revises: previous_revision_id
Create Date: 2025-11-23 14:30:00.123456

"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic
revision: str = 'abc123def456'
down_revision: Union[str, None] = 'previous_revision_id'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Apply migration changes."""
    op.add_column('users', sa.Column('bio', sa.Text(), nullable=True))
    op.add_column('users', sa.Column('avatar_url', sa.String(length=500), nullable=True))
    op.create_index('idx_users_bio', 'users', ['bio'])


def downgrade() -> None:
    """Reverse migration changes."""
    op.drop_index('idx_users_bio', table_name='users')
    op.drop_column('users', 'avatar_url')
    op.drop_column('users', 'bio')
```

**Key Components:**
- **revision**: Unique identifier for this migration
- **down_revision**: Previous migration in the chain
- **upgrade()**: Forward migration logic
- **downgrade()**: Rollback logic (should reverse upgrade())

## Running Migrations

### Development (Docker Compose)

**Check Current Migration Status:**

```bash
# Show current revision
docker compose exec api python -m alembic -c backend/alembic.ini current

# Show migration history
docker compose exec api python -m alembic -c backend/alembic.ini history

# Show pending migrations
docker compose exec api python -m alembic -c backend/alembic.ini heads
```

**Apply Migrations:**

```bash
# Upgrade to latest (most common)
docker compose exec api python -m alembic -c backend/alembic.ini upgrade head

# Upgrade one revision forward
docker compose exec api python -m alembic -c backend/alembic.ini upgrade +1

# Upgrade to specific revision
docker compose exec api python -m alembic -c backend/alembic.ini upgrade abc123def456
```

**Rollback Migrations:**

```bash
# Downgrade one revision
docker compose exec api python -m alembic -c backend/alembic.ini downgrade -1

# Downgrade to specific revision
docker compose exec api python -m alembic -c backend/alembic.ini downgrade abc123def456

# Downgrade all migrations (use with extreme caution)
docker compose exec api python -m alembic -c backend/alembic.ini downgrade base
```

**Fresh Database Setup:**

```bash
# 1. Stop all services
docker compose down

# 2. Remove database volume (deletes all data)
docker volume rm chores-tracker_mysql_data

# 3. Start services
docker compose up -d

# 4. Wait for MySQL to be ready
docker compose exec mysql mysqladmin ping -h localhost -u root -p${MYSQL_ROOT_PASSWORD}

# 5. Run migrations
docker compose exec api python -m alembic -c backend/alembic.ini upgrade head
```

### Production (Kubernetes)

Production migrations run as Kubernetes Jobs before application deployment using ArgoCD sync waves.

**Automatic Migration (Recommended):**

Migrations run automatically during deployment via the migration job:

```bash
# Check migration job status
kubectl get jobs -n chores-tracker-backend | grep migration

# View migration job logs
kubectl logs -n chores-tracker-backend job/chores-tracker-migration

# Check if migration completed successfully
kubectl get job chores-tracker-migration -n chores-tracker-backend -o jsonpath='{.status.succeeded}'
```

**Manual Migration Job (if needed):**

Use the manual migration job for troubleshooting or ad-hoc migrations:

```bash
# Apply the migration job (in backend/ directory)
kubectl apply -f run-migrations-job.yaml

# Monitor job progress
kubectl logs -n chores-tracker-backend -f job/run-migrations-job

# Check job status
kubectl get job run-migrations-job -n chores-tracker-backend

# Clean up completed job
kubectl delete job run-migrations-job -n chores-tracker-backend
```

**Migration Job Configuration** (`gitops-templates/base-apps/chores-tracker-backend/migration-job.yaml`):
- Runs with ArgoCD sync wave 1 (before deployment)
- Uses PreSync hook to run before main application
- Retries up to 4 times on failure
- 5 minute timeout
- Keeps logs for 24 hours for debugging

**Deployment Sequence:**
1. ArgoCD detects new commit in GitOps repo
2. Migration job runs (sync wave 1, PreSync hook)
3. Migration job completes successfully
4. Backend deployment updates (sync wave 2)
5. Application pods start with new schema

**Manual Migration in Production Pod (Emergency):**

```bash
# Connect to a running backend pod
kubectl exec -it -n chores-tracker-backend deployment/chores-tracker-backend -- /bin/bash

# Inside the pod, run migration
cd /app
python -m alembic -c backend/alembic.ini upgrade head

# Exit pod
exit
```

**Check Database Schema Version:**

```bash
# Connect to MySQL pod
kubectl exec -it -n chores-tracker-backend statefulset/mysql -- mysql -u root -p

# Inside MySQL, check alembic version
USE chores_tracker;
SELECT * FROM alembic_version;
```

## Common Migration Patterns

### Adding a Column

**Simple column with default:**

```python
def upgrade() -> None:
    op.add_column('users',
        sa.Column('last_login', sa.DateTime(), nullable=True)
    )

def downgrade() -> None:
    op.drop_column('users', 'last_login')
```

**Column with NOT NULL (requires default or data population):**

```python
def upgrade() -> None:
    # Add column as nullable first
    op.add_column('chores',
        sa.Column('priority', sa.Integer(), nullable=True)
    )

    # Set default value for existing rows
    op.execute("UPDATE chores SET priority = 1 WHERE priority IS NULL")

    # Make column NOT NULL
    op.alter_column('chores', 'priority', nullable=False)

def downgrade() -> None:
    op.drop_column('chores', 'priority')
```

### Modifying a Column

**Change column type:**

```python
def upgrade() -> None:
    # MySQL requires explicit type change
    op.alter_column('users', 'balance',
                    existing_type=sa.Float(),
                    type_=sa.Numeric(precision=10, scale=2),
                    existing_nullable=False)

def downgrade() -> None:
    op.alter_column('users', 'balance',
                    existing_type=sa.Numeric(precision=10, scale=2),
                    type_=sa.Float(),
                    existing_nullable=False)
```

**Rename column:**

```python
def upgrade() -> None:
    op.alter_column('chores', 'description', new_column_name='details')

def downgrade() -> None:
    op.alter_column('chores', 'details', new_column_name='description')
```

### Creating a Table

**New table with relationships:**

```python
def upgrade() -> None:
    op.create_table('chore_assignments',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('chore_id', sa.Integer(), nullable=False),
        sa.Column('assignee_id', sa.Integer(), nullable=False),
        sa.Column('is_completed', sa.Boolean(), nullable=False, server_default='0'),
        sa.Column('created_at', sa.DateTime(), nullable=False,
                  server_default=sa.text('CURRENT_TIMESTAMP')),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['chore_id'], ['chores.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['assignee_id'], ['users.id'], ondelete='CASCADE'),
        sa.UniqueConstraint('chore_id', 'assignee_id', name='unique_chore_assignee')
    )

    # Add indexes for performance
    op.create_index('idx_assignments_chore', 'chore_assignments', ['chore_id'])
    op.create_index('idx_assignments_assignee', 'chore_assignments', ['assignee_id'])

def downgrade() -> None:
    op.drop_index('idx_assignments_assignee', 'chore_assignments')
    op.drop_index('idx_assignments_chore', 'chore_assignments')
    op.drop_table('chore_assignments')
```

### Adding Indexes

**Single column index:**

```python
def upgrade() -> None:
    op.create_index('idx_users_email', 'users', ['email'])

def downgrade() -> None:
    op.drop_index('idx_users_email', 'users')
```

**Composite index:**

```python
def upgrade() -> None:
    op.create_index('idx_chores_assignee_status', 'chores',
                    ['assignee_id', 'is_completed'])

def downgrade() -> None:
    op.drop_index('idx_chores_assignee_status', 'chores')
```

**Unique index:**

```python
def upgrade() -> None:
    op.create_index('idx_users_username_unique', 'users', ['username'], unique=True)

def downgrade() -> None:
    op.drop_index('idx_users_username_unique', 'users')
```

### Data Migrations

**Populate new field from existing data:**

```python
def upgrade() -> None:
    # Add new column
    op.add_column('users', sa.Column('full_name', sa.String(200), nullable=True))

    # Migrate data using SQL
    op.execute("""
        UPDATE users
        SET full_name = CONCAT(first_name, ' ', last_name)
        WHERE first_name IS NOT NULL AND last_name IS NOT NULL
    """)

    # Alternatively, use SQLAlchemy connection
    from sqlalchemy import text
    connection = op.get_bind()
    connection.execute(text("""
        UPDATE users
        SET full_name = username
        WHERE full_name IS NULL
    """))

def downgrade() -> None:
    op.drop_column('users', 'full_name')
```

**Conditional data transformation:**

```python
def upgrade() -> None:
    from sqlalchemy.sql import table, column
    from sqlalchemy import String, Integer

    # Define table structure for data migration
    users_table = table('users',
        column('id', Integer),
        column('status', String),
        column('is_active', Integer)
    )

    # Update using SQLAlchemy expressions
    op.execute(
        users_table.update()
        .where(users_table.c.is_active == 1)
        .values(status='active')
    )

    op.execute(
        users_table.update()
        .where(users_table.c.is_active == 0)
        .values(status='inactive')
    )

def downgrade() -> None:
    # Reverse the transformation if needed
    pass
```

## Troubleshooting

### Common Issues and Solutions

#### Migration Not Detected

**Problem**: Alembic doesn't detect your model changes.

**Solutions:**
```bash
# 1. Ensure your model is imported in backend/app/db/base.py
# Check that Base.metadata includes your model

# 2. Verify model is using the correct Base
from backend.app.db.base import Base

class MyModel(Base):
    __tablename__ = "my_table"
    # ...

# 3. Check for import errors in env.py
docker compose exec api python -c "from backend.app.db.base import Base; print(Base.metadata.tables.keys())"
```

#### Alembic Version Table Missing

**Problem**: `alembic_version` table doesn't exist.

**Solutions:**
```bash
# Development: Run initial migration
docker compose exec api python -m alembic -c backend/alembic.ini upgrade head

# Production: Ensure migration job ran successfully
kubectl logs -n chores-tracker-backend job/chores-tracker-migration
```

#### Multiple Heads Detected

**Problem**: Multiple migration chains exist.

**Solutions:**
```bash
# Check migration history
docker compose exec api python -m alembic -c backend/alembic.ini history

# Merge branches (if appropriate)
docker compose exec api python -m alembic -c backend/alembic.ini merge -m "merge branches" rev1 rev2

# Or delete incorrect migration files and regenerate
```

#### Migration Fails in Production

**Problem**: Migration job fails in Kubernetes.

**Diagnosis:**
```bash
# Check job logs
kubectl logs -n chores-tracker-backend job/chores-tracker-migration

# Check job events
kubectl describe job chores-tracker-migration -n chores-tracker-backend

# Check database connectivity
kubectl exec -it -n chores-tracker-backend deployment/chores-tracker-backend -- \
  python -c "from backend.app.core.config import settings; print(settings.DATABASE_URL)"
```

**Solutions:**
```bash
# 1. Verify database credentials in secrets
kubectl get secret chores-tracker-backend-secrets -n chores-tracker-backend -o yaml

# 2. Check MySQL service is running
kubectl get pods -n chores-tracker-backend | grep mysql

# 3. Test database connection from backend pod
kubectl exec -it -n chores-tracker-backend deployment/chores-tracker-backend -- \
  mysql -h mysql -u chores_user -p

# 4. Re-run migration job manually
kubectl delete job chores-tracker-migration -n chores-tracker-backend
kubectl apply -f gitops-templates/base-apps/chores-tracker-backend/migration-job.yaml
```

#### Downgrade Fails

**Problem**: Cannot rollback migration.

**Common Causes:**
- Downgrade logic missing or incorrect
- Data loss would occur (dropped columns)
- Foreign key constraints

**Solutions:**
```bash
# 1. Review downgrade() function in migration file
# Ensure it properly reverses all upgrade() changes

# 2. For data migrations, consider:
#    - Keeping old columns temporarily
#    - Creating data backup before migration
#    - Using separate migrations for schema vs data changes

# 3. Test downgrade in development first
docker compose exec api python -m alembic -c backend/alembic.ini downgrade -1
docker compose exec api python -m alembic -c backend/alembic.ini upgrade +1
```

#### Database and Models Out of Sync

**Problem**: Database schema doesn't match SQLAlchemy models.

**Diagnosis:**
```bash
# Generate a migration to see what would change
docker compose exec api python -m alembic -c backend/alembic.ini revision --autogenerate -m "check sync"

# Review the generated file - should be empty if in sync
# Delete the file if it's empty or unwanted
```

**Solutions:**
```bash
# Option 1: Apply migrations to update database
docker compose exec api python -m alembic -c backend/alembic.ini upgrade head

# Option 2: Update models to match database (if database is correct)
# Manually edit model files to match current schema

# Option 3: Fresh start (DEVELOPMENT ONLY - LOSES DATA)
docker compose down
docker volume rm chores-tracker_mysql_data
docker compose up -d
docker compose exec api python -m alembic -c backend/alembic.ini upgrade head
```

## Best Practices

### Development Workflow

1. **Make Model Changes First**
   - Update SQLAlchemy models in `backend/app/models/`
   - Follow existing patterns and conventions
   - Add appropriate indexes and constraints

2. **Generate Migration**
   ```bash
   docker compose exec api python -m alembic -c backend/alembic.ini revision --autogenerate -m "descriptive message"
   ```

3. **Review Generated Migration**
   - Open the new file in `backend/alembic/versions/`
   - Verify upgrade() logic is correct
   - Verify downgrade() logic reverses upgrade()
   - Add any necessary data migrations
   - Check for MySQL-specific syntax issues

4. **Test Migration Locally**
   ```bash
   # Apply migration
   docker compose exec api python -m alembic -c backend/alembic.ini upgrade head

   # Verify schema
   docker compose exec mysql mysql -u root -p -e "DESCRIBE chores_tracker.your_table"

   # Test downgrade
   docker compose exec api python -m alembic -c backend/alembic.ini downgrade -1

   # Re-apply
   docker compose exec api python -m alembic -c backend/alembic.ini upgrade head
   ```

5. **Test Application**
   - Run relevant tests
   - Manually test affected features
   - Verify API endpoints work correctly

6. **Commit Migration with Code**
   ```bash
   git add backend/app/models/
   git add backend/alembic/versions/
   git commit -m "feat: add user profile fields with migration"
   ```

### Production Deployment

1. **Review Migration in PR**
   - Peer review migration logic
   - Check for breaking changes
   - Verify rollback strategy

2. **Database Backup** (for major changes)
   ```bash
   # In production, ensure MySQL backups are recent
   kubectl exec -it -n chores-tracker-backend statefulset/mysql -- \
     mysqldump -u root -p chores_tracker > backup-$(date +%Y%m%d).sql
   ```

3. **Deploy via GitOps**
   - Push code to GitHub
   - CI/CD builds new Docker image
   - ArgoCD detects changes
   - Migration job runs automatically (PreSync hook)
   - Application deployment proceeds after migration

4. **Monitor Deployment**
   ```bash
   # Watch migration job
   kubectl logs -f -n chores-tracker-backend job/chores-tracker-migration

   # Watch deployment rollout
   kubectl rollout status deployment/chores-tracker-backend -n chores-tracker-backend

   # Check application logs
   kubectl logs -f -n chores-tracker-backend deployment/chores-tracker-backend
   ```

5. **Verify in Production**
   - Check health endpoints
   - Test affected API endpoints
   - Monitor error logs
   - Verify metrics/monitoring

### Migration Hygiene

**DO:**
- Always review autogenerated migrations
- Write descriptive migration messages
- Test both upgrade and downgrade
- Include downgrade logic (even if you don't plan to use it)
- Keep migrations small and focused
- Add comments for complex logic
- Use transactions (Alembic does this automatically)
- Test with production-like data volumes

**DON'T:**
- Edit existing migration files after they're merged
- Skip downgrade logic
- Mix schema and data migrations in complex scenarios
- Use raw SQL without understanding implications
- Assume autogenerate catches everything
- Deploy migrations without testing locally
- Create migrations that depend on application code
- Hardcode environment-specific values

### Performance Considerations

**For Large Tables:**
```python
# Instead of ALTER TABLE (locks table):
def upgrade() -> None:
    # Bad: Locks table during column add
    op.add_column('large_table', sa.Column('new_field', sa.String(100)))

# Better: Use algorithm and lock options (MySQL-specific)
from alembic import op
import sqlalchemy as sa

def upgrade() -> None:
    # Add column without locking table
    op.execute("""
        ALTER TABLE large_table
        ADD COLUMN new_field VARCHAR(100),
        ALGORITHM=INPLACE, LOCK=NONE
    """)
```

**For Indexes on Large Tables:**
```python
def upgrade() -> None:
    # Create index concurrently (if supported by database)
    # Note: MySQL 5.6+ supports online index creation
    op.create_index('idx_large_table_field', 'large_table', ['field'],
                    mysql_length=255)  # Specify length for text fields
```

### Naming Conventions

**Migration Messages:**
- Use imperative mood: "add user profile fields" not "adds" or "added"
- Be specific: "add email_verified column to users" not "update users"
- Reference ticket numbers: "add families table (FEAT-123)"

**Database Objects:**
- Tables: Plural lowercase: `users`, `chore_assignments`
- Columns: Snake case: `created_at`, `assignee_id`
- Indexes: `idx_tablename_columns`: `idx_users_email`
- Foreign keys: `fk_tablename_column`: `fk_chores_creator_id`
- Unique constraints: `uq_tablename_columns`: `uq_users_email`

---

## Related Documentation

- [Backend Architecture](../architecture/BACKEND_ARCHITECTURE.md) - Database models and repository patterns
- [Environment Setup](../development/ENVIRONMENT_SETUP.md) - Local development configuration
- [Kubernetes Deployment](../deployment/KUBERNETES.md) - Production migration jobs
- [Releasing](../deployment/RELEASING.md) - Release process including migrations

---

**Last Updated**: November 23, 2024
**Alembic Version**: 1.13+
**Maintained By**: Chores Tracker Backend Team
